{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " pixelhop++ver2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmayee95/pixelhop-/blob/master/pixelhop%2B%2Bver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAqCzojFlvTD",
        "colab_type": "text"
      },
      "source": [
        "**DATA** **LOADING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyfJym7PZbqE",
        "colab_type": "code",
        "outputId": "07315cad-843f-4152-81e0-6e138c959ba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%cd \"/content/\"\n",
        "!git clone https://github.com/USC-MCL/EE569_2020Spring.git\n",
        "!pwd\n",
        "!ls EE569_2020Spring/\n",
        "%cd /content/EE569_2020Spring/"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'EE569_2020Spring' already exists and is not an empty directory.\n",
            "/content\n",
            "cross_entropy.py  lag.py   pixelhop2.pkl  __pycache__  requirements.txt\n",
            "cwSaab.py\t  llsr.py  pixelhop2.py   README.md    saab.py\n",
            "/content/EE569_2020Spring\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knSegDdvl11N",
        "colab_type": "text"
      },
      "source": [
        "**LIBRARIES LOADINNG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdhnkiuC7C1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from cross_entropy import Cross_Entropy\n",
        "from lag import LAG\n",
        "from llsr import LLSR as myLLSR\n",
        "from pixelhop2 import Pixelhop2\n",
        "import skimage\n",
        "from skimage.util import view_as_windows\n",
        "import skimage.measure\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7nX3DUw88W3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Concat(X, concatArg):\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-btuBf5ZYKhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.util import view_as_windows\n",
        "def Shrink(X, shrinkArg):\n",
        "\n",
        "  win = shrinkArg['win']\n",
        "  win=5\n",
        "  hop = shrinkArg['hop']\n",
        "  # print('Hop:',hop)\n",
        "  stride = 1\n",
        "  ch = X.shape[-1]\n",
        "  # print('Input shape:',X.shape)\n",
        "  if hop==1:\n",
        "    X = view_as_windows(X, (1,win,win,ch), (1,stride,stride,ch))\n",
        "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], -1)\n",
        "    X = skimage.measure.block_reduce(X, (1,2,2,1), np.mean)\n",
        "  if hop==2:\n",
        "    X = view_as_windows(X, (1,win,win,ch), (1,stride,stride,ch))\n",
        "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], -1)\n",
        "    X = skimage.measure.block_reduce(X, (1,2,2,1), np.mean)\n",
        "  if hop==3:\n",
        "    X = view_as_windows(X, (1,win,win,ch), (1,stride,stride,ch))\n",
        "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], -1)\n",
        "  # print(X.shape)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gviz7jkM7jm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"neighborhood construction shrink saab concat args\"\"\"\n",
        "SaabArgs = [{'num_AC_kernels':-1, 'needBias':False, 'useDC':True, 'batch':None, 'cw': True},\n",
        "                {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw': True},\n",
        "            {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw': True}]\n",
        "shrinkArgs = [{'func':Shrink, 'win':5, 'hop':1},\n",
        "              {'func': Shrink, 'win':5,'hop':2},\n",
        "              {'func': Shrink, 'win':5, 'hop':3}]\n",
        "concatArg = {'func':Concat}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_jms618Nv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "#load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "#preprocessing of data - reshape to 0-1\n",
        "x_train_50k = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn5ldmv78Umx",
        "colab_type": "code",
        "outputId": "44e1b626-cdcb-4c0f-dbbe-ebc691c8e45e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#selecting 1k images\n",
        "x_train_10k = x_train_50k[0:1000]\n",
        "print(x_train_10k.shape)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBLNgoiq-qE3",
        "colab_type": "text"
      },
      "source": [
        "Selecting 10k images with 1k of each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0OeQYB7ohQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# size = np.asarray(x_train.shape)\n",
        "# size[0] = 6250\n",
        "# data_10k = np.zeros(size)\n",
        "# ind = np.where(y_train==1)\n",
        "# k=1\n",
        "# for label in range(10):\n",
        "#   ind = np.where(y_train==label)\n",
        "#   ind = ind[0][0:625]#1/8 images\n",
        "#   for i in ind:\n",
        "#     if k>=6250:\n",
        "#       break\n",
        "#     data_10k[k,:,:,:] = x_train_50k[i,:,:,:]\n",
        "#     k+=1\n",
        "\n",
        "size = np.asarray(x_train.shape)\n",
        "size[0] = 10000\n",
        "data_10k = np.zeros(size)\n",
        "ind = np.where(y_train==1)\n",
        "k=1\n",
        "for label in range(10):\n",
        "  ind = np.where(y_train==label)\n",
        "  ind = ind[0][0:1000]#10k images\n",
        "  for i in ind:\n",
        "    if k>=10000:\n",
        "      break\n",
        "    data_10k[k,:,:,:] = x_train_50k[i,:,:,:]\n",
        "    k+=1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPvquFY5-hrT",
        "colab_type": "code",
        "outputId": "bf1d48af-7c57-4c0b-ca20-a527cb955737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_10k.shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4DiGa5BsdrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#time start\n",
        "start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQikjrV-a6i0",
        "colab_type": "code",
        "outputId": "ae52eb57-a194-41ac-ba96-913c039dcf76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#train \n",
        "phops = Pixelhop2(depth=3, TH1=0.01, TH2=0.001, SaabArgs=SaabArgs, shrinkArgs=shrinkArgs, concatArg=concatArg)\n",
        "phops.fit(data_10k)\n",
        "train_output = phops.transform(data_10k)\n",
        "test_output = phops.transform(x_test)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pixelhop2 fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pixelhop2 transform\n",
            "pixelhop2 transform\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJe3k3bxc_4f",
        "colab_type": "code",
        "outputId": "c3e8bae9-26ff-4950-bc0c-e8c8a4e801ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "  print('Output size of hop units:')\n",
        "  print('Train data:')\n",
        "  print(train_output[0].shape)\n",
        "  print(train_output[1].shape)\n",
        "  print(train_output[2].shape)\n",
        "  print('Test data:')\n",
        "  print(test_output[0].shape)\n",
        "  print(test_output[1].shape)\n",
        "  print(test_output[2].shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output size of hop units:\n",
            "Train data:\n",
            "(10000, 14, 14, 37)\n",
            "(10000, 5, 5, 125)\n",
            "(10000, 1, 1, 219)\n",
            "Test data:\n",
            "(10000, 14, 14, 37)\n",
            "(10000, 5, 5, 125)\n",
            "(10000, 1, 1, 219)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEaSUfpg8Zx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save model\n",
        "#train \n",
        "# phops = Pixelhop2(depth=3, TH1=0.01, TH2=0.001, SaabArgs=SaabArgs, shrinkArgs=shrinkArgs, concatArg=concatArg)\n",
        "#fit for 10k images\n",
        "# phops.fit(data_10k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrI01aFsHT9Z",
        "colab_type": "text"
      },
      "source": [
        "Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ry7XwemHE6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "# save model\n",
        "with open('pixelhop2.pkl','wb') as f:\n",
        "    pickle.dump(phops,f)\n",
        "# load model\n",
        "with open('pixelhop2.pkl', 'rb') as f:\n",
        "    clf2 = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Vc5XiBoubv",
        "colab_type": "code",
        "outputId": "d8fa58e0-a592-4328-b638-ca34a7936789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output = phops.transform(x_train_50k)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pixelhop2 transform\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "419KUSxLFzXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #all train data - 50k images\n",
        "# \"\"\" Train data of 50k taken in batches of 10k \"\"\"\n",
        "# out = [[]] * 5\n",
        "# for k in range(5):\n",
        "#   out[k] = phops.transform(x_train_50k[k*10000:(k+1)*10000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BPi8qhZOXQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #combining train data which are in batches\n",
        "# batch_hop = []\n",
        "# for batchi in range(5):\n",
        "#   batch_hop.append(out[batchi])\n",
        "# out1 = batch_hop[0]\n",
        "# out2 = batch_hop[1]\n",
        "# out3 = batch_hop[2]\n",
        "# out4 = batch_hop[3]\n",
        "# out5 = batch_hop[4]\n",
        "# output = list(zip(out1,out2,out3,out4,out5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ivEWNLOcgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test transform\n",
        "test_transform = test_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0YWsfLwkaRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_cross_entropy(features,y_train):\n",
        "  ce = Cross_Entropy(num_class=10, num_bin=5)\n",
        "  features = features.reshape((features.shape[0], -1))\n",
        "  print(features.shape)\n",
        "  feat_ce = np.zeros(features.shape[-1])\n",
        "  for k in range(features.shape[-1]):\n",
        "    feat_ce[k] = ce.KMeans_Cross_Entropy(features[:,k].reshape(-1,1), y_train)\n",
        "  print(\"------- DONE -------\\n\")\n",
        "  return feat_ce"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiFD27JFmOy6",
        "colab_type": "code",
        "outputId": "983176c8-02e5-4096-abdf-d2d607284df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "ce_hop_unit1 = cal_cross_entropy(output[0],y_train)\n",
        "ce_hop_unit2 = cal_cross_entropy(output[1],y_train)\n",
        "ce_hop_unit3 = cal_cross_entropy(output[2],y_train)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 7252)\n",
            "------- DONE -------\n",
            "\n",
            "(50000, 3125)\n",
            "------- DONE -------\n",
            "\n",
            "(50000, 219)\n",
            "------- DONE -------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOYS95smPDhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crossentropy_sort(crossentropy,Ns):\n",
        "  indices = crossentropy.argsort()[:1000]\n",
        "  return indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kugUfZzPYi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ns = 1000\n",
        "ce_sorted_unit1 = crossentropy_sort(ce_hop_unit1,Ns)\n",
        "ce_sorted_unit2 = crossentropy_sort(ce_hop_unit2,Ns)\n",
        "ce_sorted_unit3 = crossentropy_sort(ce_hop_unit3,Ns)\n",
        "# print(len(ce_sorted_unit3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KMOzpO3geA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_selection(data,index_array,Ns):\n",
        "  # print(data.shape[-1])\n",
        "  out = data.reshape((data.shape[0], -1))\n",
        "  print(out.shape)\n",
        "  mini = min(Ns,out.shape[-1])\n",
        "  result = np.zeros((out.shape[0],mini))\n",
        "  print(out.shape)\n",
        "  print(result.shape)\n",
        "  j=1\n",
        "  for i in index_array:\n",
        "    if j<mini:\n",
        "      result[:,j] = out[:,i]\n",
        "      j = j + 1\n",
        "    if j==1000:\n",
        "      exit\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M2Lsh24fjyA",
        "colab_type": "code",
        "outputId": "6d7f90de-d6db-45df-af63-73dcde470041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "Ns = 1000\n",
        "#feature selection\n",
        "#train data\n",
        "train_fs_hop_unit1 = feature_selection(output[0],ce_sorted_unit1,Ns)\n",
        "train_fs_hop_unit2 = feature_selection(output[1],ce_sorted_unit2,Ns)\n",
        "train_fs_hop_unit3 = feature_selection(output[2],ce_sorted_unit3,Ns)\n",
        "#test data\n",
        "test_fs_hop_unit1 = feature_selection(test_transform[0],ce_sorted_unit1,Ns)\n",
        "test_fs_hop_unit2 = feature_selection(test_transform[1],ce_sorted_unit2,Ns)\n",
        "test_fs_hop_unit3 = feature_selection(test_transform[2],ce_sorted_unit3,Ns)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 7252)\n",
            "(50000, 7252)\n",
            "(50000, 1000)\n",
            "(50000, 3125)\n",
            "(50000, 3125)\n",
            "(50000, 1000)\n",
            "(50000, 219)\n",
            "(50000, 219)\n",
            "(50000, 219)\n",
            "(10000, 7252)\n",
            "(10000, 7252)\n",
            "(10000, 1000)\n",
            "(10000, 3125)\n",
            "(10000, 3125)\n",
            "(10000, 1000)\n",
            "(10000, 219)\n",
            "(10000, 219)\n",
            "(10000, 219)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnH8BTLdQGjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lag_compute(x_train, y_train,x_test, y_test,alpha):\n",
        "    print(x_train.shape)\n",
        "    lag = LAG(encode='distance', num_clusters=[5,5,5,5,5,5,5,5,5,5], alpha=5, learner=myLLSR(onehot=False))  \n",
        "    lag.fit(x_train, y_train)\n",
        "    x_train_trans = lag.transform(x_train)\n",
        "    x_test_trans = lag.transform(x_test)\n",
        "    x_train_predprob = lag.predict_proba(x_train)\n",
        "    print('test size:', x_test.shape)\n",
        "    print(\" --> train acc: %s\"%str(lag.score(x_train, y_train)))\n",
        "    print(\" --> test acc.: %s\"%str(lag.score(x_test, y_test)))\n",
        "    print(\"------- DONE -------\\n\")\n",
        "    return x_train_trans,x_test_trans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwbaV0Pi_hth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_2d(data):\n",
        "  out = data.reshape((data.shape[0], -1))\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iLsrdn1LDR6",
        "colab_type": "code",
        "outputId": "333431a0-4d59-4915-bd6a-6aa5bc5bffe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "alpha = 5\n",
        "# y_train = y_train[0:10000]\n",
        "lag_unit1 = lag_compute(train_fs_hop_unit1,y_train,test_fs_hop_unit1, y_test,alpha)\n",
        "lag_unit2 = lag_compute(train_fs_hop_unit2,y_train,test_fs_hop_unit2, y_test,alpha)\n",
        "lag_unit3 = lag_compute(train_fs_hop_unit3,y_train,test_fs_hop_unit3, y_test,alpha)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 1000)\n",
            "test size: (10000, 1000)\n",
            " --> train acc: 0.44534\n",
            " --> test acc.: 0.3955\n",
            "------- DONE -------\n",
            "\n",
            "(50000, 1000)\n",
            "test size: (10000, 1000)\n",
            " --> train acc: 0.44998\n",
            " --> test acc.: 0.3967\n",
            "------- DONE -------\n",
            "\n",
            "(50000, 219)\n",
            "test size: (10000, 219)\n",
            " --> train acc: 0.4188\n",
            " --> test acc.: 0.4068\n",
            "------- DONE -------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y99Bm5oUHfC",
        "colab_type": "code",
        "outputId": "a5794775-12cf-4d5b-a663-93ef2a57bb26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#concatenate the outputs of lag\n",
        "lags0 = np.concatenate((lag_unit1[0],lag_unit2[0],lag_unit3[0]),axis = 1)\n",
        "lags1 = np.concatenate((lag_unit1[1],lag_unit2[1],lag_unit3[1]),axis = 1)\n",
        "\n",
        "print(lags0.shape)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM2y1pKCtb1-",
        "colab_type": "code",
        "outputId": "cd6088bf-d341-466e-aaed-91ba8d41da3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stop_time = time.time()\n",
        "total_time = stop_time-start_time\n",
        "print('Total time taken for training:',total_time)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time taken for training: 5175.023391246796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvXwCAuGdLRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from llsr import LLSR\n",
        "# reg = LLSR(onehot=True, normalize=False)\n",
        "# reg.fit(lags0, y_train)\n",
        "# X_train_reg = reg.predict_proba(lags0)\n",
        "# print(\" --> train acc: %s\"%str(reg.score(lags0, y_train)))\n",
        "# print(\" --> test acc: %s\"%str(reg.score(lags1, y_test)))\n",
        "# print(\"------- DONE -------\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZ9TT0Bd0cW",
        "colab_type": "code",
        "outputId": "1f2096a4-feb2-4642-962e-7dc518abb65f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "scaler=preprocessing.StandardScaler()\n",
        "feature = scaler.fit_transform(lags0)\n",
        "feature_test = scaler.transform(lags1)     \n",
        "   \n",
        "clf=SVC().fit(feature, y_train) \n",
        "##        clf=RandomForestClassifier(n_estimators=500,max_depth=5).fit(train_f, train_labels) \n",
        "print('***** Train ACC:', accuracy_score(y_train,clf.predict(feature)))\n",
        "print('***** Test ACC:', accuracy_score(y_test,clf.predict(feature_test)))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Train ACC: 0.67886\n",
            "***** Test ACC: 0.5043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehmBVREJsdv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "be928ccf-d5fa-480a-8e67-d7b3f82d0d31"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_moons\n",
        " \n",
        "calibrated_forest = CalibratedClassifierCV(base_estimator=RandomForestClassifier(n_estimators=100,max_depth=10,random_state=0))\n",
        "param_grid = {'base_estimator__max_depth': [2, 4, 6, 8]}\n",
        "search = GridSearchCV(calibrated_forest, param_grid, cv=5)\n",
        "search.fit(feature, y_train)\n",
        "GridSearchCV(cv=5,estimator=CalibratedClassifierCV(...),param_grid={'base_estimator__max_depth': [2, 4, 6, 8]})\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=CalibratedClassifierCV(base_estimator=Ellipsis, cv=None,\n",
              "                                              method='sigmoid'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'base_estimator__max_depth': [2, 4, 6, 8]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECYAr9NP501h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "89aff548-30df-4649-862c-763849e1bbad"
      },
      "source": [
        "print('***** Train ACC:', accuracy_score(y_train,search.predict(feature)))\n",
        "print('***** Test ACC:', accuracy_score(y_test,search.predict(feature_test)))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Train ACC: 0.51538\n",
            "***** Test ACC: 0.4377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIlVeRf3-fjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "12a35927-68b9-4035-d32b-2368195a5f93"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create the model with 100 trees\n",
        "clf = RandomForestClassifier(n_estimators=100,max_depth=100, max_features=10,random_state=0)\n",
        "                              #  bootstrap = False,\n",
        "                              #  max_features = 'auto',\n",
        "                             \n",
        "# Fit on training data\n",
        "# feature = scaler.fit_transform(lags0)\n",
        "# feature_test = scaler.transform(lags1)  \n",
        "clf = clf.fit(feature, y_train)\n",
        "\n",
        "# RandomForestClassifier(max_depth=2, random_state=0)\n",
        "# print(clf.feature_importances_)\n",
        "# print(clf.predict(lags1))\n",
        "print('***** Train ACC:', accuracy_score(y_train,clf.predict(feature)))\n",
        "print('***** Test ACC:', accuracy_score(y_test,clf.predict(feature_test)))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Train ACC: 1.0\n",
            "***** Test ACC: 0.4765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BmTh0d8j2N1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "clf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "\n",
        "feature = scaler.fit_transform(lags0)\n",
        "feature_test = scaler.transform(lags1)  \n",
        "clf = rf_random.fit(feature, y_train)\n",
        "\n",
        "# RandomForestClassifier(max_depth=2, random_state=0)\n",
        "# print(clf.feature_importances_)\n",
        "# print(clf.predict(lags1))\n",
        "print('***** Train ACC:', accuracy_score(y_train,clf.predict(feature)))\n",
        "print('***** Test ACC:', accuracy_score(y_test,clf.predict(feature_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idwOPPmLMaDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "plt.rcParams['figure.figsize'] = [10,7]\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "      print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "      print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], fmt),\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "\n",
        "# clf.predict(feature_test)\n",
        "p_test = clf.predict(feature_test)\n",
        "# clf.predict(lags1).argmax(axis=0)\n",
        "cm = confusion_matrix(y_test, p_test)\n",
        "plot_confusion_matrix(cm, list(range(10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwFAcVsa6wZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "plt.rcParams['figure.figsize'] = [10,7]\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=True,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "      print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "      print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], fmt),\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "\n",
        "# clf.predict(feature_test)\n",
        "p_test = clf.predict(feature_test)\n",
        "# clf.predict(lags1).argmax(axis=0)\n",
        "cm = confusion_matrix(y_test, p_test)\n",
        "plot_confusion_matrix(cm, list(range(10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_eeq7U-7Q0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "airplane : 0\n",
        "automobile : 1\n",
        "bird : 2\n",
        "cat : 3\n",
        "deer : 4\n",
        "dog : 5\n",
        "frog : 6\n",
        "horse : 7\n",
        "ship : 8\n",
        "truck : 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEo_s2BCUE9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "a = np.ones((3,4,5))\n",
        "b = np.ones((3,4,5))\n",
        "c = np.concatenate((a[...,np.newaxis],b[...,np.newaxis]),axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}