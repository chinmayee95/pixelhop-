{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pixelhop_stage4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmayee95/pixelhop-/blob/master/pixelhop_stage4_nsdiffforstg1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAqCzojFlvTD",
        "colab_type": "text"
      },
      "source": [
        "**DATA** **LOADING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyfJym7PZbqE",
        "colab_type": "code",
        "outputId": "82f0e636-e9d9-4210-c122-e3103c73c254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%cd \"/content/\"\n",
        "!git clone https://github.com/USC-MCL/EE569_2020Spring.git\n",
        "!pwd\n",
        "!ls EE569_2020Spring/\n",
        "%cd /content/EE569_2020Spring/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'EE569_2020Spring'...\n",
            "remote: Enumerating objects: 142, done.\u001b[K\n",
            "remote: Counting objects: 100% (142/142), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 142 (delta 84), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (142/142), 39.11 KiB | 3.26 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n",
            "/content\n",
            "cross_entropy.py  lag.py   pixelhop2.py  requirements.txt\n",
            "cwSaab.py\t  llsr.py  README.md\t saab.py\n",
            "/content/EE569_2020Spring\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knSegDdvl11N",
        "colab_type": "text"
      },
      "source": [
        "**LIBRARIES LOADINNG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdhnkiuC7C1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from cross_entropy import Cross_Entropy\n",
        "from lag import LAG\n",
        "from llsr import LLSR as myLLSR\n",
        "from pixelhop2 import Pixelhop2\n",
        "import skimage\n",
        "from skimage.util import view_as_windows\n",
        "import skimage.measure\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7nX3DUw88W3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Concat(X, concatArg):\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-btuBf5ZYKhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.util import view_as_windows\n",
        "def Shrink(X, shrinkArg):\n",
        "\n",
        "  win = shrinkArg['win']\n",
        "  win=3\n",
        "  hop = shrinkArg['hop']\n",
        "  # print('Hop:',hop)\n",
        "  stride = 1\n",
        "  ch = X.shape[-1]\n",
        "  # print('Input shape:',X.shape)\n",
        "  if hop==1:\n",
        "    X = view_as_windows(X, (1,win,win,ch), (1,stride,stride,ch))\n",
        "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], -1)\n",
        "    X = skimage.measure.block_reduce(X, (1,2,2,1), np.max)\n",
        "  if hop==2:\n",
        "    X = view_as_windows(X, (1,win,win,ch), (1,stride,stride,ch))\n",
        "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], -1)\n",
        "    X = skimage.measure.block_reduce(X, (1,2,2,1), np.max)\n",
        "  if hop==3:\n",
        "    X = view_as_windows(X, (1,win,win,ch), (1,stride,stride,ch))\n",
        "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], -1)\n",
        "    X = skimage.measure.block_reduce(X, (1,2,2,1), np.max)\n",
        "  if hop==4:\n",
        "    X = view_as_windows(X, (1,win,win,ch), (1,stride,stride,ch))\n",
        "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], -1)\n",
        "  # print(X.shape)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gviz7jkM7jm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"neighborhood construction shrink saab concat args\"\"\"\n",
        "SaabArgs = [{'num_AC_kernels':-1, 'needBias':False, 'useDC':True, 'batch':None, 'cw': True},\n",
        "                {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw': True},\n",
        "            {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw': True},\n",
        "            {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw': True}]\n",
        "shrinkArgs = [{'func':Shrink, 'win':5, 'hop':1},\n",
        "              {'func': Shrink, 'win':5,'hop':2},\n",
        "              {'func': Shrink, 'win':5,'hop':3},\n",
        "              {'func': Shrink, 'win':5, 'hop':4}]\n",
        "concatArg = {'func':Concat}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_jms618Nv8",
        "colab_type": "code",
        "outputId": "436cf7d3-9095-4e3d-b808-ce40f278a9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "#load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "#preprocessing of data - reshape to 0-1\n",
        "# x_train_50k = x_train.astype('float32')/255\n",
        "# x_test = x_test.astype('float32')/255"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pr_G0q56EVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import io, color\n",
        "x_train = color.rgb2lab(x_train)\n",
        "x_test = color.rgb2lab(x_test)\n",
        "\n",
        "x_train_50k = np.zeros(x_train.shape)\n",
        "x_train_50k[:,:,:,0] = x_train[:,:,:,0].astype('float32')/100\n",
        "x_train_50k[:,:,:,1] = x_train[:,:,:,1].astype('float32')/(-110)\n",
        "x_train_50k[:,:,:,2] = x_train[:,:,:,2].astype('float32')/110\n",
        "x_test_10k = np.zeros(x_test.shape)\n",
        "x_test_10k[:,:,:,0] = x_test[:,:,:,0].astype('float32')/100\n",
        "x_test_10k[:,:,:,1] = x_test[:,:,:,1].astype('float32')/(-110)\n",
        "x_test_10k[:,:,:,2] = x_test[:,:,:,2].astype('float32')/110\n",
        "\n",
        "x_test = x_test_10k\n",
        "x_train = x_train_50k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBLNgoiq-qE3",
        "colab_type": "text"
      },
      "source": [
        "Selecting 10k images with 1k of each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0OeQYB7ohQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = np.asarray(x_train.shape)\n",
        "size[0] = 10000\n",
        "data_10k = np.zeros(size)\n",
        "ind = np.where(y_train==1)\n",
        "k=1\n",
        "for label in range(10):\n",
        "  ind = np.where(y_train==label)\n",
        "  ind = ind[0][0:1000]#10k images\n",
        "  for i in ind:\n",
        "    if k>=10000:\n",
        "      break\n",
        "    data_10k[k,:,:,:] = x_train_50k[i,:,:,:]\n",
        "    k+=1\n",
        "\n",
        "# size = np.asarray(x_train.shape)\n",
        "# size[0] = 1560\n",
        "# data_10k = np.zeros(size)\n",
        "# ind = np.where(y_train==1)\n",
        "# k=1\n",
        "# for label in range(10):\n",
        "#   ind = np.where(y_train==label)\n",
        "#   ind = ind[0][0:156]#10k images\n",
        "#   for i in ind:\n",
        "#     if k>=1560:\n",
        "#       break\n",
        "#     data_10k[k,:,:,:] = x_train_50k[i,:,:,:]\n",
        "#     k+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPvquFY5-hrT",
        "colab_type": "code",
        "outputId": "37baa4f6-7ec9-4761-8dff-319c704fc5aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_10k.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4DiGa5BsdrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#time start\n",
        "start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQikjrV-a6i0",
        "colab_type": "code",
        "outputId": "632fbcd0-170d-4daf-cddc-7ec34ac55490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "#train \n",
        "phops = Pixelhop2(depth=4, TH1=0.0001, TH2=0.00001, SaabArgs=SaabArgs, shrinkArgs=shrinkArgs, concatArg=concatArg)\n",
        "phops.fit(data_10k)\n",
        "train_output = phops.transform(data_10k)\n",
        "test_transform = phops.transform(x_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pixelhop2 fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pixelhop2 transform\n",
            "pixelhop2 transform\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJe3k3bxc_4f",
        "colab_type": "code",
        "outputId": "8e60db68-4bf9-4a77-d2b9-f7b4596ba282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "  print('Output size of hop units:')\n",
        "  print('Train data:')\n",
        "  print(train_output[0].shape)\n",
        "  print(train_output[1].shape)\n",
        "  print(train_output[2].shape)\n",
        "  print(train_output[3].shape)\n",
        "\n",
        "  print('Test data:')\n",
        "  print(test_transform[0].shape)\n",
        "  print(test_transform[1].shape)\n",
        "  print(test_transform[2].shape)\n",
        "  print(test_transform[3].shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output size of hop units:\n",
            "Train data:\n",
            "(10000, 15, 15, 27)\n",
            "(10000, 7, 7, 239)\n",
            "(10000, 3, 3, 1295)\n",
            "(10000, 1, 1, 3621)\n",
            "Test data:\n",
            "(10000, 15, 15, 27)\n",
            "(10000, 7, 7, 239)\n",
            "(10000, 3, 3, 1295)\n",
            "(10000, 1, 1, 3621)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrI01aFsHT9Z",
        "colab_type": "text"
      },
      "source": [
        "Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ry7XwemHE6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "# save model\n",
        "with open('pixelhop2.pkl','wb') as f:\n",
        "    pickle.dump(phops,f)\n",
        "# load model\n",
        "with open('pixelhop2.pkl', 'rb') as f:\n",
        "    clf2 = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Vc5XiBoubv",
        "colab_type": "code",
        "outputId": "225e4096-0943-4d4c-fe32-e9c7893a7052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output = phops.transform(x_train_50k)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pixelhop2 transform\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0YWsfLwkaRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_cross_entropy(features,y_train):\n",
        "  ce = Cross_Entropy(num_class=10, num_bin=5)\n",
        "  features = features.reshape((features.shape[0], -1))\n",
        "  print(features.shape)\n",
        "  feat_ce = np.zeros(features.shape[-1])\n",
        "  for k in range(features.shape[-1]):\n",
        "    feat_ce[k] = ce.compute(features[:,k].reshape(-1,1), y_train)\n",
        "  print(\"------- DONE -------\\n\")\n",
        "  return feat_ce"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiFD27JFmOy6",
        "colab_type": "code",
        "outputId": "d7eccc36-9167-4dc7-f72f-16101de45b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "ce_hop_unit1 = cal_cross_entropy(output[0],y_train)\n",
        "ce_hop_unit2 = cal_cross_entropy(output[1],y_train)\n",
        "ce_hop_unit3 = cal_cross_entropy(output[2],y_train)\n",
        "ce_hop_unit4 = cal_cross_entropy(output[3],y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 6075)\n",
            "------- DONE -------\n",
            "\n",
            "(50000, 11711)\n",
            "------- DONE -------\n",
            "\n",
            "(50000, 11655)\n",
            "------- DONE -------\n",
            "\n",
            "(50000, 3621)\n",
            "------- DONE -------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOYS95smPDhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crossentropy_sort(crossentropy):\n",
        "  # Ns = ns*\n",
        "  indices = crossentropy.argsort()\n",
        "  # [:Ns]\n",
        "  return indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kugUfZzPYi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ce_sorted_unit1 = crossentropy_sort(ce_hop_unit1)\n",
        "ce_sorted_unit2 = crossentropy_sort(ce_hop_unit2)\n",
        "ce_sorted_unit3 = crossentropy_sort(ce_hop_unit3)\n",
        "ce_sorted_unit4 = crossentropy_sort(ce_hop_unit4)\n",
        "\n",
        "# print(len(ce_sorted_unit3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KMOzpO3geA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_selection(data,index_array,ns):\n",
        "  # print(index_array.shape[-1])\n",
        "  out = data.reshape((data.shape[0], -1))\n",
        "  print(out.shape)\n",
        "  if ns<=1:\n",
        "      Ns = int(ns*index_array.shape[-1])\n",
        "  else:\n",
        "    Ns=ns\n",
        "  mini = min(Ns,out.shape[-1])\n",
        "  result = np.zeros((out.shape[0],mini))\n",
        "  print(out.shape)\n",
        "  print(result.shape)\n",
        "  j=1\n",
        "  for i in index_array:\n",
        "    if j<mini:\n",
        "      result[:,j] = out[:,i]\n",
        "      j = j + 1\n",
        "    if j==Ns:\n",
        "      exit\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M2Lsh24fjyA",
        "colab_type": "code",
        "outputId": "af348208-65dc-4865-92d2-c2fe208d12e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "Ns = 3000\n",
        "#feature selection\n",
        "#train data\n",
        "train_fs_hop_unit1 = feature_selection(output[0],ce_sorted_unit1,4750)\n",
        "train_fs_hop_unit2 = feature_selection(output[1],ce_sorted_unit2,Ns)\n",
        "train_fs_hop_unit3 = feature_selection(output[2],ce_sorted_unit3,Ns)\n",
        "train_fs_hop_unit4 = feature_selection(output[3],ce_sorted_unit4,Ns)\n",
        "#test data\n",
        "test_fs_hop_unit1 = feature_selection(test_transform[0],ce_sorted_unit1,4750)\n",
        "test_fs_hop_unit2 = feature_selection(test_transform[1],ce_sorted_unit2,Ns)\n",
        "test_fs_hop_unit3 = feature_selection(test_transform[2],ce_sorted_unit3,Ns)\n",
        "test_fs_hop_unit4 = feature_selection(test_transform[3],ce_sorted_unit4,Ns)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 6075)\n",
            "(50000, 6075)\n",
            "(50000, 4750)\n",
            "(50000, 11711)\n",
            "(50000, 11711)\n",
            "(50000, 3000)\n",
            "(50000, 11655)\n",
            "(50000, 11655)\n",
            "(50000, 3000)\n",
            "(50000, 3621)\n",
            "(50000, 3621)\n",
            "(50000, 3000)\n",
            "(10000, 6075)\n",
            "(10000, 6075)\n",
            "(10000, 4750)\n",
            "(10000, 11711)\n",
            "(10000, 11711)\n",
            "(10000, 3000)\n",
            "(10000, 11655)\n",
            "(10000, 11655)\n",
            "(10000, 3000)\n",
            "(10000, 3621)\n",
            "(10000, 3621)\n",
            "(10000, 3000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnH8BTLdQGjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lag_compute(x_train, y_train,x_test, y_test,alpha=10):\n",
        "    print(x_train.shape)\n",
        "    lag = LAG(encode='distance', num_clusters=[5,5,5,5,5,5,5,5,5,5], alpha=10, learner=myLLSR(onehot=False))  \n",
        "    lag.fit(x_train, y_train)\n",
        "    x_train_trans = lag.transform(x_train)\n",
        "    x_test_trans = lag.transform(x_test)\n",
        "    x_train_predprob = lag.predict_proba(x_train)\n",
        "    print('test size:', x_test.shape)\n",
        "    print(\" --> train acc: %s\"%str(lag.score(x_train, y_train)))\n",
        "    print(\" --> test acc.: %s\"%str(lag.score(x_test, y_test)))\n",
        "    print(\"------- DONE -------\\n\")\n",
        "    return x_train_trans,x_test_trans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwbaV0Pi_hth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_2d(data):\n",
        "  out = data.reshape((data.shape[0], -1))\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdR2Ol7tOmoz",
        "colab_type": "code",
        "outputId": "deb4d007-810e-4523-c169-7045ea2ad196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "alpha = 10\n",
        "# y_train = y_train[0:10000]\n",
        "lag_unit1 = lag_compute(train_fs_hop_unit1,y_train,test_fs_hop_unit1, y_test,alpha)\n",
        "# lag_unit2 = lag_compute(train_fs_hop_unit2,y_train,test_fs_hop_unit2, y_test,alpha)\n",
        "# lag_unit3 = lag_compute(train_fs_hop_unit3,y_train,test_fs_hop_unit3, y_test,alpha)\n",
        "# lag_unit4 = lag_compute(train_fs_hop_unit4,y_train,test_fs_hop_unit4, y_test,alpha)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 4750)\n",
            "test size: (10000, 4750)\n",
            " --> train acc: 0.5536\n",
            " --> test acc.: 0.3495\n",
            "------- DONE -------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C6Il1rd6xFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e7d2b8b9-f02d-4d08-80de-335988f0137f"
      },
      "source": [
        "lag_unit2 = lag_compute(train_fs_hop_unit2,y_train,test_fs_hop_unit2, y_test,alpha)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3000)\n",
            "test size: (10000, 3000)\n",
            " --> train acc: 0.64402\n",
            " --> test acc.: 0.5315\n",
            "------- DONE -------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDMVQt2a61Td",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "10cc84be-1280-4742-afd7-5f5c8280cd27"
      },
      "source": [
        "lag_unit3 = lag_compute(train_fs_hop_unit3,y_train,test_fs_hop_unit3, y_test,alpha)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3000)\n",
            "test size: (10000, 3000)\n",
            " --> train acc: 0.68248\n",
            " --> test acc.: 0.5735\n",
            "------- DONE -------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8mvCpDp64FW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b3f46715-c8c1-424a-8c33-bf09b453207f"
      },
      "source": [
        "lag_unit4 = lag_compute(train_fs_hop_unit4,y_train,test_fs_hop_unit4, y_test,alpha)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3000)\n",
            "test size: (10000, 3000)\n",
            " --> train acc: 0.70378\n",
            " --> test acc.: 0.6097\n",
            "------- DONE -------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzqVxBVAOVla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7d788870-384d-4c50-8f8e-ea4e421ea9d3"
      },
      "source": [
        "#concatenate the outputs of lag\n",
        "lags0 = np.concatenate((lag_unit1[0],lag_unit2[0],lag_unit3[0],lag_unit4[0]),axis = 1)\n",
        "lags1 = np.concatenate((lag_unit1[1],lag_unit2[1],lag_unit3[1],lag_unit4[1]),axis = 1)\n",
        "print('LAG at each stage dimension resuced to:',lag_unit1[0].shape[-1])\n",
        "print('Output of combined LAG:',lags0.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LAG at each stage dimension resuced to: 50\n",
            "Output of combined LAG: (50000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlQQaOGtOYe7",
        "colab_type": "code",
        "outputId": "4debd50a-d47b-45c6-c947-38c511a28715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stop_time = time.time()\n",
        "total_time = stop_time-start_time\n",
        "print('Total time taken for training:',total_time)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time taken for training: 3441.21865773201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V74erfROcAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d0768a22-1970-48ed-fd16-5baaa1464906"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "scaler=preprocessing.StandardScaler()\n",
        "feature = scaler.fit_transform(lags0)\n",
        "feature_test = scaler.transform(lags1)     \n",
        "   \n",
        "clf=SVC().fit(feature, y_train) \n",
        "##        clf=RandomForestClassifier(n_estimators=500,max_depth=5).fit(train_f, train_labels) \n",
        "print('***** Train ACC:', accuracy_score(y_train,clf.predict(feature)))\n",
        "print('***** Test ACC:', accuracy_score(y_test,clf.predict(feature_test)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Train ACC: 0.89028\n",
            "***** Test ACC: 0.6313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itapax9gOftC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b85670df-4240-4ae2-b3aa-e5d92d12ffb8"
      },
      "source": [
        "#classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(max_depth=40, random_state=0)\n",
        "feature = scaler.fit_transform(lags0)\n",
        "feature_test = scaler.transform(lags1)  \n",
        "clf = clf.fit(feature, y_train)\n",
        "\n",
        "# RandomForestClassifier(max_depth=2, random_state=0)\n",
        "# print(clf.feature_importances_)\n",
        "# print(clf.predict(lags1))\n",
        "print('***** Train ACC:', accuracy_score(y_train,clf.predict(feature)))\n",
        "print('***** Test ACC:', accuracy_score(y_test,clf.predict(feature_test)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Train ACC: 0.99994\n",
            "***** Test ACC: 0.6354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhZwu4KaBARx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "1a736cbb-3841-404c-eea7-12755983e41a"
      },
      "source": [
        "#classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(max_depth=40, n_jobs=10, verbose=1,random_state=4)\n",
        "feature = scaler.fit_transform(lags0)\n",
        "feature_test = scaler.transform(lags1)  \n",
        "clf = clf.fit(feature, y_train)\n",
        "\n",
        "# RandomForestClassifier(max_depth=2, random_state=0)\n",
        "# print(clf.feature_importances_)\n",
        "# print(clf.predict(lags1))\n",
        "print('***** Train ACC:', accuracy_score(y_train,clf.predict(feature)))\n",
        "print('***** Test ACC:', accuracy_score(y_test,clf.predict(feature_test)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n",
            "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:   17.5s finished\n",
            "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Train ACC: 0.99986\n",
            "***** Test ACC: 0.632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcfmWHebzfVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "plt.rcParams['figure.figsize'] = [10,7]\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "      print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "      print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], fmt),\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "\n",
        "# clf.predict(feature_test)\n",
        "p_test = clf.predict(feature_test)\n",
        "# clf.predict(lags1).argmax(axis=0)\n",
        "cm = confusion_matrix(y_test, p_test)\n",
        "plot_confusion_matrix(cm, list(range(10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwFAcVsa6wZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "plt.rcParams['figure.figsize'] = [10,7]\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=True,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "      print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "      print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], fmt),\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "\n",
        "# clf.predict(feature_test)\n",
        "p_test = clf.predict(feature_test)\n",
        "# clf.predict(lags1).argmax(axis=0)\n",
        "cm = confusion_matrix(y_test, p_test)\n",
        "plot_confusion_matrix(cm, list(range(10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_eeq7U-7Q0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "airplane : 0\n",
        "automobile : 1\n",
        "bird : 2\n",
        "cat : 3\n",
        "deer : 4\n",
        "dog : 5\n",
        "frog : 6\n",
        "horse : 7\n",
        "ship : 8\n",
        "truck : 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMftRPSBoCVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}