{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_pixelhop2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmayee95/pixelhop-/blob/master/final8_pixelhop2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAqCzojFlvTD",
        "colab_type": "text"
      },
      "source": [
        "**DATA** **LOADING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyfJym7PZbqE",
        "colab_type": "code",
        "outputId": "69889cb6-a249-44c7-dc45-e568f5f9f865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%cd \"/content/\"\n",
        "!git clone https://github.com/USC-MCL/EE569_2020Spring.git\n",
        "!pwd\n",
        "!ls EE569_2020Spring/\n",
        "%cd /content/EE569_2020Spring/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'EE569_2020Spring'...\n",
            "remote: Enumerating objects: 142, done.\u001b[K\n",
            "remote: Counting objects: 100% (142/142), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 142 (delta 84), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (142/142), 39.11 KiB | 9.78 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n",
            "/content\n",
            "cross_entropy.py  lag.py   pixelhop2.py  requirements.txt\n",
            "cwSaab.py\t  llsr.py  README.md\t saab.py\n",
            "/content/EE569_2020Spring\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knSegDdvl11N",
        "colab_type": "text"
      },
      "source": [
        "**LIBRARIES LOADINNG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdhnkiuC7C1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from cross_entropy import Cross_Entropy\n",
        "from lag import LAG\n",
        "from llsr import LLSR as myLLSR\n",
        "from pixelhop2 import Pixelhop2\n",
        "import skimage\n",
        "from skimage.util import view_as_windows\n",
        "import skimage.measure\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7nX3DUw88W3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Concat(X, concatArg):\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-btuBf5ZYKhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.util import view_as_windows\n",
        "def Shrink(X, shrinkArg):\n",
        "\n",
        "  win = shrinkArg['win']\n",
        "  win=5\n",
        "  hop = shrinkArg['hop']\n",
        "  # print('Hop:',hop)\n",
        "  stride = 1\n",
        "  ch = X.shape[-1]\n",
        "  # print('Input shape:',X.shape)\n",
        "  if hop==1:\n",
        "    X = view_as_windows(X, (1,win,win,ch), (1,stride,stride,ch))\n",
        "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], -1)\n",
        "    X = skimage.measure.block_reduce(X, (1,2,2,1), np.max)\n",
        "  if hop==2:\n",
        "    X = view_as_windows(X, (1,win,win,ch), (1,stride,stride,ch))\n",
        "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], -1)\n",
        "    X = skimage.measure.block_reduce(X, (1,2,2,1), np.max)\n",
        "  if hop==3:\n",
        "    X = view_as_windows(X, (1,win,win,ch), (1,stride,stride,ch))\n",
        "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], -1)\n",
        "  # print(X.shape)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gviz7jkM7jm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"neighborhood construction shrink saab concat args\"\"\"\n",
        "SaabArgs = [{'num_AC_kernels':-1, 'needBias':False, 'useDC':True, 'batch':None, 'cw': True},\n",
        "                {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw': True},\n",
        "            {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw': True}]\n",
        "shrinkArgs = [{'func':Shrink, 'win':5, 'hop':1},\n",
        "              {'func': Shrink, 'win':5,'hop':2},\n",
        "              {'func': Shrink, 'win':5, 'hop':3}]\n",
        "concatArg = {'func':Concat}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_jms618Nv8",
        "colab_type": "code",
        "outputId": "0190511b-80fe-44c0-ed19-73bee6660257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "#load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "#preprocessing of data - reshape to 0-1\n",
        "# x_train_50k = x_train.astype('float32')/255\n",
        "# x_test = x_test.astype('float32')/255"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVd6xMjNRmVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import io, color\n",
        "x_train = color.rgb2lab(x_train)\n",
        "x_test = color.rgb2lab(x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M-c4-ooRxXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.max(np.max(x_train_50k,axis=1))\n",
        "# np.min(np.min(x_train_50k,axis=1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utcQ6jABUmXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_50k = np.zeros(x_train.shape)\n",
        "x_train_50k[:,:,:,0] = x_train[:,:,:,0].astype('float32')/100\n",
        "x_train_50k[:,:,:,1] = x_train[:,:,:,1].astype('float32')/(-110)\n",
        "x_train_50k[:,:,:,2] = x_train[:,:,:,2].astype('float32')/110\n",
        "x_test_10k = np.zeros(x_test.shape)\n",
        "x_test_10k[:,:,:,0] = x_test[:,:,:,0].astype('float32')/100\n",
        "x_test_10k[:,:,:,1] = x_test[:,:,:,1].astype('float32')/(-110)\n",
        "x_test_10k[:,:,:,2] = x_test[:,:,:,2].astype('float32')/110"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMSG3x9UVDiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = x_test_10k\n",
        "x_train = x_train_50k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBLNgoiq-qE3",
        "colab_type": "text"
      },
      "source": [
        "Selecting 10k images with 1k of each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_ia6DeVYvzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def YCbCr(image):\n",
        "\n",
        "#   R=image[:,:,:,0]\n",
        "#   G=image[:,:,:,1]\n",
        "#   B=image[:,:,:,2]\n",
        "#   Kry = 0.299\n",
        "#   Kby = 0.114\n",
        "#   Kgy = 1 - (Kry + Kby) \n",
        "#   Kru = - Kry \n",
        "#   Kgu = - Kgy \n",
        "#   Kbu = 1 - Kby \n",
        "#   Krv = 1 - Kry \n",
        "#   Kgv = -Kgy \n",
        "#   Kbv = -Kby\n",
        "#   Y = Kry * R + Kgy * G + Kby * B \n",
        "#   Cb = Kru * R + Kgu * G + Kbu * B \n",
        "#   Cr = Krv * R + Kgv * G + Kbv * B\n",
        "#   image_new=np.zeros(image.shape)\n",
        "#   image_new[:,:,:,0] = Y\n",
        "#   image_new[:,:,:,1] = Cb\n",
        "#   image_new[:,:,:,2] = Cr\n",
        "\n",
        "#   return image_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0OeQYB7ohQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_train_50k = YCbCr(x_train)\n",
        "# x_test_n = YCbCr(x_test)\n",
        "# x_test = x_test_n\n",
        "\n",
        "size = np.asarray(x_train.shape)\n",
        "size[0] = 10000\n",
        "data_10k = np.zeros(size)\n",
        "ind = np.where(y_train==1)\n",
        "k=1\n",
        "for label in range(10):\n",
        "  ind = np.where(y_train==label)\n",
        "  ind = ind[0][0:1000]#10k images\n",
        "  for i in ind:\n",
        "    if k>=10000:\n",
        "      break\n",
        "    data_10k[k,:,:,:] = x_train_50k[i,:,:,:]\n",
        "    k+=1\n",
        "\n",
        "# size = np.asarray(x_train.shape)\n",
        "# size[0] = 6250\n",
        "# data_10k = np.zeros(size)\n",
        "# ind = np.where(y_train==1)\n",
        "# k=1\n",
        "# for label in range(10):\n",
        "#   ind = np.where(y_train==label)\n",
        "#   ind = ind[0][0:625]#10k images\n",
        "#   for i in ind:\n",
        "#     if k>=6250:\n",
        "#       break\n",
        "#     data_10k[k,:,:,:] = x_train_50k[i,:,:,:]\n",
        "#     k+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPvquFY5-hrT",
        "colab_type": "code",
        "outputId": "b6ade867-f06f-4860-fa36-8f8cad283c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_10k.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4DiGa5BsdrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#time start\n",
        "start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQikjrV-a6i0",
        "colab_type": "code",
        "outputId": "29c9d1cc-67a6-4409-ba57-8b389ae95dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#train \n",
        "phops = Pixelhop2(depth=3, TH1=0.01, TH2=0.001, SaabArgs=SaabArgs, shrinkArgs=shrinkArgs, concatArg=concatArg)\n",
        "phops.fit(data_10k)\n",
        "train_output = phops.transform(data_10k)\n",
        "test_transform = phops.transform(x_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pixelhop2 fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_incremental_pca.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "  explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pixelhop2 transform\n",
            "pixelhop2 transform\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJe3k3bxc_4f",
        "colab_type": "code",
        "outputId": "de64d6e0-0c20-4352-db2b-ff34227ea6c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "  print('Output size of hop units:')\n",
        "  print('Train data:')\n",
        "  print(train_output[0].shape)\n",
        "  print(train_output[1].shape)\n",
        "  print(train_output[2].shape)\n",
        "  print('Test data:')\n",
        "  print(test_transform[0].shape)\n",
        "  print(test_transform[1].shape)\n",
        "  print(test_transform[2].shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output size of hop units:\n",
            "Train data:\n",
            "(10000, 14, 14, 40)\n",
            "(10000, 5, 5, 113)\n",
            "(10000, 1, 1, 167)\n",
            "Test data:\n",
            "(10000, 14, 14, 40)\n",
            "(10000, 5, 5, 113)\n",
            "(10000, 1, 1, 167)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrI01aFsHT9Z",
        "colab_type": "text"
      },
      "source": [
        "Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ry7XwemHE6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "# save model\n",
        "with open('pixelhop2.pkl','wb') as f:\n",
        "    pickle.dump(phops,f)\n",
        "# load model\n",
        "with open('pixelhop2.pkl', 'rb') as f:\n",
        "    clf2 = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Vc5XiBoubv",
        "colab_type": "code",
        "outputId": "7e621c89-893e-4648-b601-0c13e2c52b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output = phops.transform(x_train_50k)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pixelhop2 transform\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0YWsfLwkaRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_cross_entropy(features,y_train):\n",
        "  ce = Cross_Entropy(num_class=10, num_bin=5)\n",
        "  features = features.reshape((features.shape[0], -1))\n",
        "  print(features.shape)\n",
        "  feat_ce = np.zeros(features.shape[-1])\n",
        "  for k in range(features.shape[-1]):\n",
        "    feat_ce[k] = ce.compute(features[:,k].reshape(-1,1), y_train)\n",
        "  print(\"------- DONE -------\\n\")\n",
        "  return feat_ce"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiFD27JFmOy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7be8787f-0242-42f4-b192-5a86e432c033"
      },
      "source": [
        "ce_hop_unit1 = cal_cross_entropy(output[0],y_train)\n",
        "ce_hop_unit2 = cal_cross_entropy(output[1],y_train)\n",
        "ce_hop_unit3 = cal_cross_entropy(output[2],y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 7840)\n",
            "------- DONE -------\n",
            "\n",
            "(50000, 2825)\n",
            "------- DONE -------\n",
            "\n",
            "(50000, 167)\n",
            "------- DONE -------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T2VhPiHrEz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crossentropy_sort(crossentropy):\n",
        "  # Ns = ns*\n",
        "  indices = crossentropy.argsort()\n",
        "  # [:Ns]\n",
        "  return indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaaBAeJQq3iT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ns = 0.8\n",
        "ce_sorted_unit1 = crossentropy_sort(ce_hop_unit1)\n",
        "ce_sorted_unit2 = crossentropy_sort(ce_hop_unit2)\n",
        "ce_sorted_unit3 = crossentropy_sort(ce_hop_unit3)\n",
        "# print(len(ce_sorted_unit3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KMOzpO3geA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_selection(data,index_array,ns):\n",
        "  # print(index_array.shape[-1])\n",
        "  out = data.reshape((data.shape[0], -1))\n",
        "  print(out.shape)\n",
        "  if ns<1:\n",
        "      Ns = int(ns*index_array.shape[-1])\n",
        "  else:\n",
        "    Ns=ns\n",
        "  mini = min(Ns,out.shape[-1])\n",
        "  result = np.zeros((out.shape[0],mini))\n",
        "  print(out.shape)\n",
        "  print(result.shape)\n",
        "  j=1\n",
        "  for i in index_array:\n",
        "    if j<mini:\n",
        "      result[:,j] = out[:,i]\n",
        "      j = j + 1\n",
        "    if j==Ns:\n",
        "      exit\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M2Lsh24fjyA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "60a4c91b-7195-4dfb-ceba-0faf5cec1aa9"
      },
      "source": [
        "Ns = 3200\n",
        "#feature selection\n",
        "#train data\n",
        "train_fs_hop_unit1 = feature_selection(output[0],ce_sorted_unit1,Ns)\n",
        "train_fs_hop_unit2 = feature_selection(output[1],ce_sorted_unit2,Ns)\n",
        "train_fs_hop_unit3 = feature_selection(output[2],ce_sorted_unit3,Ns)\n",
        "#test data\n",
        "test_fs_hop_unit1 = feature_selection(test_transform[0],ce_sorted_unit1,Ns)\n",
        "test_fs_hop_unit2 = feature_selection(test_transform[1],ce_sorted_unit2,Ns)\n",
        "test_fs_hop_unit3 = feature_selection(test_transform[2],ce_sorted_unit3,Ns)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 7840)\n",
            "(50000, 7840)\n",
            "(50000, 3200)\n",
            "(50000, 2825)\n",
            "(50000, 2825)\n",
            "(50000, 2825)\n",
            "(50000, 167)\n",
            "(50000, 167)\n",
            "(50000, 167)\n",
            "(10000, 7840)\n",
            "(10000, 7840)\n",
            "(10000, 3200)\n",
            "(10000, 2825)\n",
            "(10000, 2825)\n",
            "(10000, 2825)\n",
            "(10000, 167)\n",
            "(10000, 167)\n",
            "(10000, 167)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnH8BTLdQGjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lag_compute(x_train, y_train,x_test, y_test,alpha=10):\n",
        "    print(x_train.shape)\n",
        "    lag = LAG(encode='distance', num_clusters=[10,10,10,10,10,10,10,10,10,10], alpha=10, learner=myLLSR(onehot=False))  \n",
        "    lag.fit(x_train, y_train)\n",
        "    x_train_trans = lag.transform(x_train)\n",
        "    x_test_trans = lag.transform(x_test)\n",
        "    x_train_predprob = lag.predict_proba(x_train)\n",
        "    print('test size:', x_test.shape)\n",
        "    print(\" --> train acc: %s\"%str(lag.score(x_train, y_train)))\n",
        "    print(\" --> test acc.: %s\"%str(lag.score(x_test, y_test)))\n",
        "    print(\"------- DONE -------\\n\")\n",
        "    return x_train_trans,x_test_trans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwbaV0Pi_hth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_2d(data):\n",
        "  out = data.reshape((data.shape[0], -1))\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdR2Ol7tOmoz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "1334a4d4-99b8-4318-965c-a87ad7cb4bbb"
      },
      "source": [
        "alpha = 10\n",
        "# y_train = y_train[0:10000]\n",
        "lag_unit1 = lag_compute(train_fs_hop_unit1,y_train,test_fs_hop_unit1, y_test,alpha)\n",
        "lag_unit2 = lag_compute(train_fs_hop_unit2,y_train,test_fs_hop_unit2, y_test,alpha)\n",
        "lag_unit3 = lag_compute(train_fs_hop_unit3,y_train,test_fs_hop_unit3, y_test,alpha)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3200)\n",
            "test size: (10000, 3200)\n",
            " --> train acc: 0.51112\n",
            " --> test acc.: 0.36\n",
            "------- DONE -------\n",
            "\n",
            "(50000, 2825)\n",
            "test size: (10000, 2825)\n",
            " --> train acc: 0.64148\n",
            " --> test acc.: 0.536\n",
            "------- DONE -------\n",
            "\n",
            "(50000, 167)\n",
            "test size: (10000, 167)\n",
            " --> train acc: 0.48988\n",
            " --> test acc.: 0.4752\n",
            "------- DONE -------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzqVxBVAOVla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6b64dde1-605d-4900-c576-9f8004004b4e"
      },
      "source": [
        "#concatenate the outputs of lag\n",
        "lags0 = np.concatenate((lag_unit1[0],lag_unit2[0],lag_unit3[0]),axis = 1)\n",
        "lags1 = np.concatenate((lag_unit1[1],lag_unit2[1],lag_unit3[1]),axis = 1)\n",
        "print('LAG at each stage dimension resuced to:',lag_unit1[0].shape[-1])\n",
        "print('Output of combined LAG:',lags0.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LAG at each stage dimension resuced to: 100\n",
            "Output of combined LAG: (50000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlQQaOGtOYe7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56b237f5-eb52-4d50-b4d3-70981f68a990"
      },
      "source": [
        "stop_time = time.time()\n",
        "total_time = stop_time-start_time\n",
        "print('Total time taken for training:',total_time)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time taken for training: 5843.868452072144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V74erfROcAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "373b5895-9009-4eaf-c9ef-11a3d52a0e3f"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "scaler=preprocessing.StandardScaler()\n",
        "feature = scaler.fit_transform(lags0)\n",
        "feature_test = scaler.transform(lags1)     \n",
        "   \n",
        "clf=SVC().fit(feature, y_train) \n",
        "##        clf=RandomForestClassifier(n_estimators=500,max_depth=5).fit(train_f, train_labels) \n",
        "print('***** Train ACC:', accuracy_score(y_train,clf.predict(feature)))\n",
        "print('***** Test ACC:', accuracy_score(y_test,clf.predict(feature_test)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Train ACC: 0.88562\n",
            "***** Test ACC: 0.6068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itapax9gOftC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "06f160c6-e1a9-41e8-b2dc-03ae6b186348"
      },
      "source": [
        "#classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(max_depth=40, n_jobs=10, verbose=1,random_state=4)\n",
        "feature = scaler.fit_transform(lags0)\n",
        "feature_test = scaler.transform(lags1)  \n",
        "clf = clf.fit(feature, y_train)\n",
        "\n",
        "# RandomForestClassifier(max_depth=2, random_state=0)\n",
        "# print(clf.feature_importances_)\n",
        "# print(clf.predict(lags1))\n",
        "print('***** Train ACC:', accuracy_score(y_train,clf.predict(feature)))\n",
        "print('***** Test ACC:', accuracy_score(y_test,clf.predict(feature_test)))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n",
            "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   18.6s\n",
            "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:   36.4s finished\n",
            "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Train ACC: 1.0\n",
            "***** Test ACC: 0.5809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfCaeuTvk3gv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd830ae-a508-4193-9d3e-2c9e108255b0"
      },
      "source": [
        "n_estimators=n_estimators, max_depth=None, verbose=1, n_jobs=10"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-626d8799838c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    n_estimators=n_estimators, max_depth=None, verbose=1, n_jobs=10\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to keyword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfrL1pHP3Uvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # Plot confusion matrix\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# import matplotlib.pyplot as plt\n",
        "# import itertools\n",
        "# plt.rcParams['figure.figsize'] = [10,7]\n",
        "\n",
        "# def plot_confusion_matrix(cm, classes,\n",
        "#                           normalize=False,\n",
        "#                           title='Confusion matrix',\n",
        "#                           cmap=plt.cm.Blues):\n",
        "\n",
        "#   if normalize:\n",
        "#       cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "#       print(\"Normalized confusion matrix\")\n",
        "#   else:\n",
        "#       print('Confusion matrix, without normalization')\n",
        "\n",
        "#   print(cm)\n",
        "\n",
        "#   plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "#   plt.title(title)\n",
        "#   plt.colorbar()\n",
        "#   tick_marks = np.arange(len(classes))\n",
        "#   plt.xticks(tick_marks, classes, rotation=45)\n",
        "#   plt.yticks(tick_marks, classes)\n",
        "\n",
        "#   fmt = '.2f' if normalize else 'd'\n",
        "#   thresh = cm.max() / 2.\n",
        "#   for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "#       plt.text(j, i, format(cm[i, j], fmt),\n",
        "#                horizontalalignment=\"center\",\n",
        "#                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "#   plt.tight_layout()\n",
        "#   plt.ylabel('True label')\n",
        "#   plt.xlabel('Predicted label')\n",
        "#   plt.show()\n",
        "\n",
        "# # clf.predict(feature_test)\n",
        "# p_test = clf.predict(feature_test)\n",
        "# # clf.predict(lags1).argmax(axis=0)\n",
        "# cm = confusion_matrix(y_test, p_test)\n",
        "# plot_confusion_matrix(cm, list(range(10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwFAcVsa6wZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Plot confusion matrix\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# import matplotlib.pyplot as plt\n",
        "# import itertools\n",
        "# plt.rcParams['figure.figsize'] = [10,7]\n",
        "\n",
        "# def plot_confusion_matrix(cm, classes,\n",
        "#                           normalize=True,\n",
        "#                           title='Confusion matrix',\n",
        "#                           cmap=plt.cm.Blues):\n",
        "\n",
        "#   if normalize:\n",
        "#       cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "#       print(\"Normalized confusion matrix\")\n",
        "#   else:\n",
        "#       print('Confusion matrix, without normalization')\n",
        "\n",
        "#   print(cm)\n",
        "\n",
        "#   plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "#   plt.title(title)\n",
        "#   plt.colorbar()\n",
        "#   tick_marks = np.arange(len(classes))\n",
        "#   plt.xticks(tick_marks, classes, rotation=45)\n",
        "#   plt.yticks(tick_marks, classes)\n",
        "\n",
        "#   fmt = '.2f' if normalize else 'd'\n",
        "#   thresh = cm.max() / 2.\n",
        "#   for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "#       plt.text(j, i, format(cm[i, j], fmt),\n",
        "#                horizontalalignment=\"center\",\n",
        "#                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "#   plt.tight_layout()\n",
        "#   plt.ylabel('True label')\n",
        "#   plt.xlabel('Predicted label')\n",
        "#   plt.show()\n",
        "\n",
        "# # clf.predict(feature_test)\n",
        "# p_test = clf.predict(feature_test)\n",
        "# # clf.predict(lags1).argmax(axis=0)\n",
        "# cm = confusion_matrix(y_test, p_test)\n",
        "# plot_confusion_matrix(cm, list(range(10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_eeq7U-7Q0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "airplane : 0\n",
        "automobile : 1\n",
        "bird : 2\n",
        "cat : 3\n",
        "deer : 4\n",
        "dog : 5\n",
        "frog : 6\n",
        "horse : 7\n",
        "ship : 8\n",
        "truck : 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMftRPSBoCVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}